# 基于 AI 的思考

## 在软件研发领域

核心：

定义时：成本、效率
运行时：体验、性能、跨平台(高性能的跨平台框架)

管理：效能

1、全栈化改革的目标是减少中间的协同成本，让一个开发者能完成更多任务，同时将更专业的人才放在更需要专业技能的岗位上，这推动了菜鸟整个技术体系的不断演进。
思考：
（1）全栈化 VS 专业性
（2）全栈岗位：成本 VS 效能
（3）专家型开发人员（稀缺） VS 横向能力较强（借助现有工具，可以在全栈领域创造更大价值）

注意：本质是价值
前端开发的本质并未改变

2、虽然 AI 可以完成大量工作，甚至高达 80% 的工作量，但那剩下的 20% 才是最为关键的部分，而这正是我们人类的优势所在。

3、对于个人而言，是否选择大前端路线取决于职业发展规划。有些同学适合专注于某一领域，成为专家型开发人员，这部分人才在行业中依然稀缺。有些同学则横向能力较强，借助现有工具，可以在全栈领域创造更大价值。

4、推动底层技术变革，首先需要评估技术的收益和成本，确保其能为团队带来实质价值。其次，工程师需要具备专业能力，能够通过技术经验和行业趋势做出准确判断。最后，技术的选择还需与现有生态互补，避免重复造轮子。

## 工程学

比如建立多个小型概念验证项目来确定各种方法的影响因子与限制条件。这就是工程学的魅力所在，先充分理解约束条件、再尝试新方法以改善用户感受。

## 维度

审视自己的价值观和决策认识论

实际上，让 Web 体验变好的唯一方法就是关注用户体验——具体来讲就是关注边缘用例的体验。技术方案总是来了又去，而起到决定性作用的永远是谁更关注用户感受。

任何一家希望在原有 Web 网站基础之上开发出高性能移动体验的公司，都最好认真研究一下 Trusted Web Activities 还有 PWABuilder。如果这些方法不起作用，Capacitor 和 Cordova 也有类似的功能。

数据才是真正的“底牌”

当然，作为“大模型货架”，像 Amazon Bedrock 一般的产品，对外实现功能完备，保障模型品类更新及时，仍然只是“第一步”。随着企业对 AI 的应用逐渐进入“深水期”，更多的竞争差异会从数据层面体现出来。这也是为什么，同样是接入 DeepSeek 落地应用的企业，有的正在享受“技术红利”，有的还在原地踏步。一方面，低质量的数据根本无法“养活”像 DeepSeek 这样的大模型。比如，某企业在部署 DeepSeek 后，希望通过 AI 模型优化其推荐系统，但由于训练数据中包含了大量噪声或错误信息，模型生成的推荐结果准确性大幅下降。另一方面，由于数据通常被分散在多个工具和系统中，企业需要重复进行数据准备和参数调优等步骤，效率低下。工具的不统一，也使得企业难以及时全面监控和分析数据，无法最大化发挥模型优势。DeepSeek 只是个开始，为“AI 应用落地”吹哨的除了“大模型货架”和端到端的技术方案，还需要数据基础设施的进一步升级。这几年，无论是亚马逊云科技、微软 Azure 还是谷歌云，都在提升自己的数据处理能力。以亚马逊云科技为例，其数据底座 S3 不仅支持海量数据的存储和管理，还通过引入 S3 Intelligent-Tiering 和 S3 Glacier Instant Retrieval 等功能，降低数据存储成本，为 AI 模型的训练和实时数据分析提供基础。为了简化数据集成和 ETL 流程，亚马逊云科技推出了 Glue，不仅支持数据的自动化集成，还通过引入 Glue DataBrew 和 Glue Elastic Views 等功能，进一步简化了数据管道的构建和管理。这种端到端的数据集成能力，使得企业能够更高效地整合多源数据，为 AI 模型的训练和优化提供高质量的数据支持。在 AI 开发领域，亚马逊云科技在 2024 年 re:Invent 上宣布 SageMaker 再度进化，为所有数据分析和 AI 提供一站式服务。下一代 SageMaker 几乎涵盖包括数据探索、准备与集成、大数据处理、快速 SQL 分析、机器学习模型开发与训练，以及生成式 AI 应用程序开发所需要的全部组件。过往企业在开发 AI 应用时，通常使用多种工具来完成不同的任务，例如使用 comet 跟踪和管理训练实验，使用 deepchecks 评估模型质量，使用 fiddler 监控生产环境中的模型性能，以及使用 LAKERA 保护 AI 系统免受安全威胁。这些工具往往分散在不同的平台中，开发者需要在它们间频繁切换，这种重复劳动既降低了工作效率，又增加了出错的风险。下一代 SageMaker 通过集成 comet、deepchecks、fiddler 和 LAKERA 等 AI 应用程序，支持从实验跟踪、模型评估到性能监控和安全防护的全流程管理。至于最基本的数据质量问题，为了帮助企业构建高质量的数据管道，下一代 SageMaker 提供了自动化数据清洗工具，能够识别并修复数据中的噪声、缺失值和异常值。同时还集成了实时数据质量监控功能，能够动态检测数据流中的质量问题，提供即时反馈。如果说 Amazon Bedrock 解决的是大模型落地的效率问题，那么下一代 SageMaker 解决的就是资源利用和数据分析等大模型落地的速度问题。而这些，既是企业通过 AI 实现商业价值的关键驱动力，也是云厂商在 AI 时代的底牌。

[AI 将如何颠覆传统软件开发团队](https://mp.weixin.qq.com/s/gEBx0OG-CzUChAyQgtd9AQ)

在谈到 AI 和机器学习（ML）时，Gosling 也对专业术语提出了批评：“对于 AI 和机器学习，我最难接受的就是它们的名称。”在他看来，与其使用这些具有误导性、将其与人类推理能力关联起来的迷惑表述，“高级统计方法”反而是更准确的字眼。Gosling 认为这些技术也仅仅是“极其复杂的锤子和螺丝刀”：仍然是人类手中的工具，而不是能够威胁就业的自主系统。

AI 对一些就业的冲击，是否也说名了，中国大部分人之前做的工作，可替代性更强（和发达国家比）；

三是将个人行业经验转化为训练、优化 AI 模型的“知识燃料”，聚焦于 AI 不擅长的决策创新、情感连接和复杂问题解决，开辟新角色。

利用生成式 AI 帮助工程师们快速理解公司内部的旧有代码库。

## 观点

Factory AI 由理论物理学博士 Matan Grinberg 和曾任 Hugging Face 及微软数据科学家的 Eno Reyes 共同创立的公司打造。

Matan Grinberg 认为 AI 的到来将使程序员的工作重心转向更高层次，并且“可解决的问题总量”也会因此变得更多。未来那些具备系统性思维、深入理解底层原理并善于利用 AI 工具的程序员，将更具价值。
**所以关键在于：你是否具备一种能力——进入一个复杂领域后，迅速搞清楚核心基础是什么，哪些细节是你必须弄懂的，哪些可以暂时模糊理解，但依然能继续往前推进。**
我唯一能说的是，在思考未来时，我会尽量回归初衷。我们搞软件工程的初衷并不是为了写代码本身。我们不是为了代码而写代码，而是为了造出我们想造的东西。
我们写程序，是为了借助计算机这种比人类快得多的“计算机器”完成我们的目标。计算只是手段，不是目的。真正的目标，是用它来构建连接世界的工具、解决现实的问题。我们想要实现的是有意义的终点。比如，我们想要模拟某些科学现象，以便研发新药；又比如，我们只是想让打车这件事变得更高效，不必再等上三十分钟才叫到出租车。
这些才是我们的目的，而手段是软件，因为我们想用机器来完成这些事，而不是仅依靠人工系统。为了与机器交流，我们不得不学习一种非常精确的语言——编程语言。后来我们慢慢让这种语言变得越来越抽象，因为直接用比特与机器交流实在是太低效了。用更高层次的抽象语言，效率反而更高。所以我认为这个趋势还会持续下去。过去，我们必须深入学习编程，才能知道如何与机器协作。但现在我们正开始“抽离”出来，重新关注我们真正想实现的目标。
